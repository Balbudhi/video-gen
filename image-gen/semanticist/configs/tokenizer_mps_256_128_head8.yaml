trainer:
  target: semanticist.engine.diffusion_trainer.DiffusionTrainer
  params:
    num_epoch: 200
    valid_size: 64

    # Learning Rate and Optimizer
    blr: 2.5e-5
    cosine_lr: True
    warmup_epochs: 5
    max_grad_norm: 1.0

    # Mac-Optimized Data Loading
    batch_size: 32
    grad_accum_steps: 4
    num_workers: 4          
    pin_memory: False       # False because MPS uses Unified Memory

    # Precision Strategy
    precision: "bf16"

    enable_ema: True
    save_every: 1000
    sample_every: 2000       # Frequent sampling for qualitative validation

    eval_fid: False
    fid_every: 999999999    # Disable FID calc (too slow locally)

    test_num_slots: 8
    # cfg: 3.0
    cfg: 1.0
    compile: False          # torch.compile is currently unstable on MPS

    result_folder: "./output/tokenizer_mps256_128_head8_sdv_phase2"
    log_dir: "./output/tokenizer_mps256_128_head8_sdv_phase2/logs"

    model:
      target: semanticist.stage1.diffuse_slot.DiffuseSlot
      params:
        eval_fid: False
        encoder: "vit_base_patch16"
        enc_img_size: 256
        enc_causal: True

        num_slots: 128
        slot_dim: 16
        norm_slots: True

        # DiT Architecture: Small variant for MPS throughput
        dit_model: "DiT-S-4"
        num_sampling_steps: "250"

        # vae: "xwen99/mar-vae-kl16"
        vae: "stabilityai/sd-vae-ft-ema"

        enable_nest: False
        enable_nest_after: 50
        
        prefix_loss_p: 0.3
        prefix_loss_lambda: 0.10
        prefix_loss_ks: [1, 2, 4, 8]
        prefix_loss_start_epoch: 50

        nest_mode: "bimodal"
        nest_head_cutoff: 8
        nest_head_anchors: [1, 2, 4, 8]
        nest_p_full: 0.30
        nest_p_head: 0.70
        nest_p_head_late: null
        nest_p_head_late_start_epoch: 0

        tail_block_norm: True
        tail_block_norm_after: 0

        use_repa: False     # Disable REPA to save VRAM/Compute
        ckpt_path: null

    dataset:
      target: semanticist.utils.datasets.ImageNet
      params:
        root: ../datasets/looney_tunes256
        split: train
        aug: randcrop
        img_size: 256

    test_dataset:
      target: semanticist.utils.datasets.ImageNet
      params:
        root: ../datasets/looney_tunes256
        split: val
        aug: centercrop
        img_size: 256

